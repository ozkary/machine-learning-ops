{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from typing import List\n",
    "from numpy import ndarray\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise Requirements\n",
    "\n",
    "- Update the dependencies\n",
    "\n",
    "```\n",
    "pip install -r requirements.txt\n",
    "\n",
    "```\n",
    "\n",
    "- Download the files for Jan and Feb 2022 running these commands:\n",
    "\n",
    "```\n",
    "python3 discovery.py --url https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-01.parquet --prefix yellow\n",
    "python3 discovery.py --url https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-02.parquet --prefix yellow\n",
    "```\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Downloading the data\n",
    "\n",
    "Read the data for January 2022. \n",
    "How many columns are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Jan 2022 Columns 19\n"
     ]
    }
   ],
   "source": [
    "def read_parquet(file_path : str) -> pd.DataFrame: \n",
    "    df = pd.read_parquet(file_path, engine=\"fastparquet\")\n",
    "    return df\n",
    "\n",
    "file_jan = \"../data/yellow_tripdata_2022-01.parquet\"\n",
    "df_jan = read_parquet(file_jan)    \n",
    "print(F\" Jan 2022 Columns {df_jan.columns.size}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Computing duration\n",
    "\n",
    "Now let's compute the duration variable. It should contain the duration of a ride in minutes.\n",
    "What's the standard deviation of the trips duration in January?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Deviation of Jan 2022 Trip Durations: 46.45%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def add_duration(df : pd.DataFrame) -> pd.DataFrame:\n",
    "     # calculate the duration of each trip in the series\n",
    "    df['duration'] = df['tpep_dropoff_datetime'] - df['tpep_pickup_datetime']  \n",
    "    df.duration = df.duration.apply(lambda td: td.total_seconds() / 60)    \n",
    "    return df\n",
    "\n",
    "def get_duration_std_dev(df : pd.DataFrame) -> float:    \n",
    "    # Calculate the standard deviation of trip durations\n",
    "    std_dev = df['duration'].std()\n",
    "    return std_dev\n",
    "\n",
    "#  add the duration series\n",
    "df_jan = add_duration(df_jan)\n",
    "std_dev_jan =get_duration_std_dev(df_jan)\n",
    "print(\"Standard Deviation of Jan 2022 Trip Durations: {:.2f}%\".format(std_dev_jan))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Dropping outliers\n",
    "\n",
    "Next, we need to check the distribution of the duration variable. There are some outliers. Let's remove them and keep only the records where the duration was between 1 and 60 minutes (inclusive).\n",
    "\n",
    "What fraction of the records left after you dropped the outliers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage of Rows Remaining: 98.28%\n"
     ]
    }
   ],
   "source": [
    "def drop_outliers(df : pd.DataFrame, min = 1, max = 60) -> pd.DataFrame:\n",
    "    # filter the DataFrame to keep durations min and max\n",
    "    df = df[(df['duration'] >= min) & (df['duration'] <= max)]\n",
    "    return df\n",
    "\n",
    "def get_percentage_change(df_original : pd.DataFrame, df_filtered : pd.DataFrame) -> float:\n",
    "    return (len(df_filtered) / len(df_original)) * 100\n",
    "\n",
    "df_jan_filtered = drop_outliers(df_jan)\n",
    "# calculate the percentage of rows remaining \n",
    "percentage_remaining = get_percentage_change(df_jan, df_jan_filtered)\n",
    "print(\"percentage of Rows Remaining: {:.2f}%\".format(percentage_remaining))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot encoding\n",
    "\n",
    "Let's apply one-hot encoding to the pickup and dropoff location IDs. We'll use only these two features for our model.\n",
    "\n",
    "- Turn the dataframe into a list of dictionaries\n",
    "- Fit a dictionary vectorizer\n",
    "- Get a feature matrix from it\n",
    "- What's the dimensionality of this matrix (number of columns)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "# fit and transform (gets the feature matrix) the data using the DictVectorizer\n",
    "# It's important to create a single instance of DictVectorizer and use that instance for both the training and test data.\n",
    "dv = DictVectorizer()\n",
    "\n",
    "def get_feature_matrix(dv:DictVectorizer, df : pd.DataFrame, features: List[str], training = True) -> ndarray:\n",
    "    # apply one-hot encoding to pickup and dropoff location IDs    \n",
    "    df_features = df[features].astype(str)    \n",
    "\n",
    "    # convert the one-hot encoded DataFrame to a list of dictionaries\n",
    "    data_dict = df_features.to_dict(orient='records')\n",
    "    \n",
    "    # apply a fit_transoform for training data, else use only transform for test/new data\n",
    "    X_encoded = dv.fit_transform(data_dict) if training else dv.transform(data_dict)     \n",
    "    \n",
    "    # X_encoded is the feauture matrix and is the input to the ML model. \n",
    "    # each row of the feature matrix represents an individual observation, \n",
    "    # each column represents a specific feature or variable    \n",
    "    # print(\"Feature matrix:\", X_encoded.toarray())\n",
    "\n",
    "    return X_encoded\n",
    "\n",
    "#  get the feature matrix\n",
    "features = [\"PULocationID\", \"DOLocationID\"]\n",
    "target = [\"duration\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of cols: 515\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train = get_feature_matrix(dv, df_jan_filtered, features)\n",
    "\n",
    "#  get the target values\n",
    "y_train = df_jan_filtered[\"duration\"].values\n",
    "\n",
    "# get the dimensionality of the feature matrix\n",
    "num_rows, num_cols = X_train.shape\n",
    "\n",
    "# print(\"number of rows:\", num_rows)\n",
    "print(\"number of cols:\", num_cols)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a model\n",
    "\n",
    "Now let's use the feature matrix from the previous step to train a model.\n",
    "\n",
    "- Train a plain linear regression model with default parameters\n",
    "- Calculate the Root Mean Square Error (RMSE) of the model on the training data\n",
    "\n",
    "What's the RMSE on train?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Train of Jan 2022 Trip Durations: 6.99%\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def calculate_rmse(model: LinearRegression, X: ndarray, y: List[int]) -> float:\n",
    "    \n",
    "    # Make predictions on the test data\n",
    "    y_pred = model.predict(X)\n",
    "    \n",
    "    # Calculate the RMSE\n",
    "    # rmse = np.sqrt(mean_squared_error(y, y_pred, squared=False))\n",
    "    rmse = mean_squared_error(y, y_pred, squared=False)\n",
    "\n",
    "    return rmse\n",
    "\n",
    "def get_model(model_name: str, X: ndarray, y: List[int] ) -> LinearRegression:\n",
    "\n",
    "    model_name = F'../models/{model_name}.pkl'\n",
    "    # model = joblib.load(model_name)\n",
    "    lr = LinearRegression()\n",
    "    model = lr.fit(X, y)\n",
    "    # save the trained model to a file\n",
    "    joblib.dump(model, model_name)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "model = get_model(\"yellow_2022_linear_model\", X_train, y_train)\n",
    "\n",
    "rmse_train = calculate_rmse(model, X_train, y_train)\n",
    "print(\"RMSE Train of Jan 2022 Trip Durations: {:.2f}%\".format(rmse_train))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model\n",
    "\n",
    "Now let's apply this model to the validation dataset (February 2022).\n",
    "\n",
    "What's the RMSE on validation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_feb = \"../data/yellow_tripdata_2022-02.parquet\"\n",
    "df_feb = read_parquet(file_feb)   \n",
    "df_feb = add_duration(df_feb)\n",
    "df_feb_filtered = drop_outliers(df_feb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Test of Feb 2022 Trip Durations: 7.79%\n"
     ]
    }
   ],
   "source": [
    "#  get the test/evaluation data\n",
    "X_test = get_feature_matrix(dv, df_feb_filtered, features, False)\n",
    "\n",
    "#  get the test target values\n",
    "y_test = df_feb_filtered[\"duration\"].values\n",
    "\n",
    "# calculate the rmse for Feb 2022\n",
    "rmse_test = calculate_rmse(model, X_test, y_test)\n",
    "print(\"RMSE Test of Feb 2022 Trip Durations: {:.2f}%\".format(rmse_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
